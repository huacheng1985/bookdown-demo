# Many Facet Rasch Model {#MFR_model}


This chapter provides a basic overview of the Many-Facet Rasch Model (MFRM; Linacre, 1989 - ADD REFERENCE!!), along with guidance for analyzing data with the MFRM using R. We use the TAM package (Robitzsch et al., 2020) for all of the analyses in this chapter. To demonstrate the analyses, we use data from two performance assessments. In the first example, we demonstrate how to apply the MFRM to multi-faceted data that are stored in wide format (one row for each subject). Then, we demonstrate how to apply the MFRM to multi-faceted data that are stored in long format (multiple rows for each subject). Both examples use data from a writing performance assessment in which which 21 raters scored 372 students' essays. After the analyses are complete, we present an example description of the results. The chapter concludes with a challenge exercise.

## Many-Facet Rasch Model

The Many-Facet Rasch Model was developed by Mike Linacre in his dissertation research with Ben Wright at the University of Chicago (Linacre, 1989). Since that time, it has been widely used across many measurement contexts.

The MFRM (Linacre, 1989) is an extension of the Rasch family of models that allows researchers to include additional variables of interest ("facets") besides items and persons. Bond and Fox (XXXX) defined facets as "Aspects of the measurement process that “routinely and systematically interpose themselves between the ability of the candidates and the difficulty of the test” (p. 167). Examples of interposing variables that could be modeled as facets include raters in a constructed-response assessment, participant demographic variables (e.g., gender, race/ethnicity, best language), item type, or domains in an analytic scoring rubric for constructed-response items.

A general equation for the MFRM is:

XXXXX

The model is user-specified and can be applied to any ordinal scoring scheme (XXXXX).


### Model Requirements

The MFRM is based on the same requirements of unidimensionality, local independence, and invariance that we discussed in Chapter 2 for the dichotomous Rasch model. In practice, researchers should evaluate item responses for evidence that they approximate Rasch model requirements before examining model estimates in detail. Chapter 3 included details about model-data fit analysis procedures that can also be applied to the MFRM.

# Example 1: Running the Many-Facet Rasch Model for Wide-Format Data using the TAM Package

In the next section, we provide a step-by-step demonstration of a MFRM analysis using the TAM package for R. We encourage readers to use the example data set that is provided in the online supplement to conduct the analysis along with us.

For this first example, we use a subset of the writing assessment data that only includes students' scores related to the style of their writing. In the second example in this chapter, we use students' scores related to four domains: Style, Organization, Conventions, and Sentence Formation.

## Getting Started

To get started with the TAM package, view the citation information, and then install and load it into your R environment using the following code:

```{r}
citation("TAM")
# install.packages("TAM")
#install.packages("TAM")
library("TAM")
```

To facilitate the example analysis, we will also use the *WrightMap* package (Torres Irribarra & Freund, 2014):
  
WrightMap:
```{r}
citation("WrightMap")
# install.packages("WrightMap")
library("WrightMap") 
```

## Prepare the data for analysis

Now that we have installed and loaded the packages to our R session, we are ready to import the data. We will use the function *read.csv()* to import the comma-separated values (.csv) file that contains the data for the first example. We encourage readers to use their preferred method for importing data files into R or R Studio.

Please note that if you use *read.csv()* to import the data, you will need to specify the file path to the location at which the data file is stored on your computer or set your working directory to the folder in which you have saved the data.

First, we will import the data using *read.csv()* and store it in an object called *writing_wide*:

```{r}
style <- read.csv("style_ratings.csv")
```
The style ratings file is in *wide format*, because there is one row for each of the 372 unique students. Next, we will explore the data using descriptive statistics using the *summary()* function:
```{r}
summary(style)
```
From the summary of *style*, we can see there are no missing data. In addition, we can get a general sense of the scales, range, and distribution of each variable in the data set. For example, we can see that the data include student identification numbers, a language subgroup variable, and ratings from 21 raters. We can see that student identification numbers range from 3 to 1574. There are two language subgroups: Subgroup 1 (language = 1) indicates that students' best langauge is English, and subgroup 2 (language = 2) indicates that students' best language is a language other than English. The minimum rating from each rater was *x* = 0, and the maximum rating was *x* = 3.

Please note that the TAM package requires that the lowest observation for item responses is equal to zero. In our data, this property is already present. If the lowest category is something other than zero, the analyst will need to recode the responses as we have done in previous chapters.

## Specify the components of the MFR model

Now, we are ready to run the MFRM on the style ratings. Because the MFRM equation is user-specified, we need to define the components of the model. First, we will create an object called *facets* in which we specify the facets in the model. By default, the TAM package treats the variables that make up the columns of our item response matrix as an "item" facet. In our example, raters function as pseudo-items. Accordingly, raters make up the first facet in our analysis. Our second facet will be student language subgroups. We specify this facet and save it in a dataframe called *facets*:

```{r}
facets <- style[,"language", drop=FALSE] 
```

Next we need to identify the indicator variable for the object of measurement (i.e., subject). In our example, students are the object of measurement. We will save the student identification numbers in a vector called *students*:

```{r}
students <- style$student
```

Finally, we need to specify the response matrix. We do so by extacting the raters' scores for each student to a dataframe called *ratings*:

```{r}
ratings <- style[, -c(1:2)]
```

## Specify the MFRM formula:

Next, we need to specify the formula for our MFRM. To keep things simple for now, we will use a rating scale model specification of the MFRM.

[EXPLAIN MODEL SPECIFICATION]

```{r}
style_RS_MFRM <- ~ item + language + step
```

[sw stopped editing here on April 14!]






















## Run the PC-MFR model




PC_MFR_model <- tam.mml.mfr(resp = resp, facets = facets, formulaA = PC_MFR_formula, pid = pid)


# Facet results:

facet.estimates <- PC_MFR_model$xsi.facets # all facets together
item.estimates <- subset(facet.estimates, facet.estimates$facet == "item")
education.estimates <- subset(facet.estimates, facet.estimates$facet == "education")
education_threshold.estimates <- subset(facet.estimates, facet.estimates$facet == "step:education")


### Center the item parameter estimates for ease of interpretation
uncentered.item.locations_PCMFR <- item.estimates$xsi
centered.item.locations_PCMFR <- scale(uncentered.item.locations_PCMFR, scale = FALSE)
summary(centered.item.locations_PCMFR)

### Examine education locations:
summary(education.estimates$xsi)

### Examine person locations:
person.estimates <- tam.wle(PC_MFR_model)
theta <- person.estimates$theta
summary(theta)

### Store person parameters and their standard errors in a dataframe object:
person.locations_PCMFR <- cbind.data.frame(cesd$id,
                                          person.estimates$theta,
                                          person.estimates$error)

names(person.locations_PCMFR) <- c("id", "theta", "SE")

### Subtract the original (uncentered) item mean location from the person locations:
person.locations_PCMFR$theta_adjusted <- person.locations_PCMFR$theta - mean(uncentered.item.locations_PCMFR)




We will use the *PCM()* function to run the model and store the results in an object called *PCM.science*. Then, we will request a summary of the model results using the *summary()* function:






# Example 2:


```{r}
# Input the data from the .csv file:
writing <- read.csv("writing.csv")
```

Note that the data are in *long* format: This means that there are multiple rows for each element within the object of measurement. In the case of our example data, this means that there are multiple rows for each student. Each row includes one rater's ratings of one student on all four of the domains in the assessment: Style, Organization, Conventions, and Sentence Formation. 

Next, we will explore the data using descriptive statistics using the *summary()* function:

```{r}
summary(writing)
```

From the summary of *writing*, we can see there are no missing data. In addition, we can get a general sense of the scales, range, and distribution of each variable in the data set.

We can see that student identification numbers range from 3 to 1574. We can identify the number of unique students in the data using the following code:
```{r}
length(unique(writing$student))
```
There are 372 unique student identification numbers in our data. Returning to the summary of the writing data, we can see that the minimum rating on each domain was *x* = 1, and the maximum rating was *x* = 4. 

Next, let's prepare the data for analysis with TAM by shifting the scale so that the lowest category equals zero:

```{r}
writing[, -c(1:2)] <- writing[, -c(1:2)] - 1
```






We will run a Rating Scale formulation of the model first.

```{r}
# First, ensure that the data are ordered by the object of measurement:
georgia_writing <- georgia_writing[order(georgia_writing$student),]

## set up the MFR model analysis:

# identify the facets besides items:
writing.facets <- georgia_writing[, c("rater"),drop=FALSE] 

# identify the object of measurement:
writing.pid <- georgia_writing$student 

# identify the response matrix:
writing.resp <- georgia_writing[,-c(1:2)]

# specify the RS-MFR model:
RS.writing.formula <- ~ item + rater + step 

# Run the RS-MFR model:

writing.model <- tam.mml.mfr(resp=writing.resp,facets=writing.facets,
                             formulaA=RS.writing.formula, pid=writing.pid)

# Request a summary of the model results:
summary(writing.model)

# Save the facet estimates:
facet.estimates <- writing.model$xsi.facets # all facets together

domain.estimates <- subset(facet.estimates, facet.estimates$facet == "item")

rater.estimates <- subset(facet.estimates, facet.estimates$facet == "rater")

threshold.estimates <- subset(facet.estimates, facet.estimates$facet == "step")


```

### Student Estimates
```{r}
## Student Estimates

# Student fit:
person.fit <- tam.personfit(writing.model)
person.fit # Check the person infit/outfit

# Student achievement estimates:
student.ach <- tam.wle(writing.model)
theta <- student.ach$theta
summary(theta)
```

### Domain/Rater Fit:
```{r}
## Compute rater and domain fit statistics 
# (note that these are called "items" in the TAM code).
rater_domain.fit <- msq.itemfit(writing.model)
summary(rater_domain.fit) # fit is shown for the rater*item combinations
```

### Plots

#### The WrightMap 

```{r}
library(WrightMap)
IRT.WrightMap(writing.model)
```

#### Simple histograms of estimates:

```{r}

graphics.off()

min.logit <- floor(min(theta))
max.logit <- ceiling(max(theta))

par(mfrow = c(3, 1))
hist(theta, xlim = c(min.logit, max.logit), main = "Student Locations", col = "aquamarine", 
     axes = FALSE, xlab = "Logits")
abline(v = c(threshold.estimates$xsi[1],
             threshold.estimates$xsi[2],
             threshold.estimates$xsi[3]), col = c("blue", "red", "orange"), lwd = 2)
axis(1, at = seq(min.logit, max.logit, by = 1), labels = seq(min.logit, max.logit, by = 1))
axis(2)


hist(rater.estimates$xsi, xlim = c(min.logit, max.logit), main = "Rater Locations", col = "hot pink", 
     axes = FALSE, xlab = "Logits")

abline(v = c(threshold.estimates$xsi[1],
             threshold.estimates$xsi[2],
             threshold.estimates$xsi[3]), col = c("blue", "red", "orange"), lwd = 2)
axis(1, at = seq(min.logit, max.logit, by = 1), labels = seq(min.logit, max.logit, by = 1))
axis(2)

hist(domain.estimates$xsi, xlim = c(min.logit, max.logit), main = "Domain Locations", col = "purple", 
     axes = FALSE, xlab = "Logits")

abline(v = c(threshold.estimates$xsi[1],
             threshold.estimates$xsi[2],
             threshold.estimates$xsi[3]), col = c("blue", "red", "orange"), lwd = 2)
axis(1, at = seq(min.logit, max.logit, by = 1), labels = seq(min.logit, max.logit, by = 1))
axis(2)
legend("right", c("tau 1", "tau 2", "tau 3"), lty = 1, 
       col = c("blue", "red", "orange"), lwd = 2)



```


#### Plot Item Response Curves

```{r}
# Plot Item Response curves
graphics.off()
plot(writing.model, type="items")


# Plot expected response curves
graphics.off()
plot(writing.model, type="expected")
```


